{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fad704c-3723-471e-ad10-c51385d07d8d",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f85717b-7f12-4da2-98ff-ffe63f69480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import time\n",
    "import pickle\n",
    "import shap; shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e1590f-3871-4508-8f26-90b734a3f7e8",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010fb950-72b7-4dda-b0d5-b973c6f831d2",
   "metadata": {},
   "source": [
    "*Dataset format*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582a8784-5ab4-4117-83a8-037c9a0ba8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "diabetes_data = pd.read_csv(\"../data/diabetes_binary_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "print(f\"DATA HEAD:\\n{diabetes_data.head()}\\n\")\n",
    "print(f\"DATA COLUMNS:\\n{list(diabetes_data.columns)}\\n\")\n",
    "print(f\"DATA MISSING VALUES:\\n{diabetes_data.isna().any()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b26e98a-8874-48f6-9295-0839002c1b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ROWS: {diabetes_data.shape[0]}\")\n",
    "print(f\"COLUMNS: {diabetes_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ccc942-d60a-4809-a6f7-b68093f006a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(diabetes_data.columns):\n",
    "    print(f\"COLUMN NAME: {col} | COLUMN DTYPE: {diabetes_data.dtypes.iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5ea111-c202-495f-8fc0-0602d52df10f",
   "metadata": {},
   "source": [
    "*Target variable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b21021-f715-45ab-8714-e13532b6ac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_data.drop(columns=[\"Diabetes_binary\"])\n",
    "y = diabetes_data[\"Diabetes_binary\"]\n",
    "    \n",
    "y_vis = y.replace({0 : \"Non-Diabetic\", 1 : \"(Pre-)Diabetic\"})\n",
    "counts = y_vis.value_counts()\n",
    "print(f\"Value counts:\\n{counts}\\n\")\n",
    "print(f\"Class proportions:\\n{counts / len(y_vis)}\\n\")\n",
    "\n",
    "sns.countplot(data=y_vis)\n",
    "plt.title(\"Distribution of Diabetic Status in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"Diabetic Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/target.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef17dd96-3f4c-435c-9969-8527bc11330e",
   "metadata": {},
   "source": [
    "*Features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d16f6-4f9a-484b-952b-6037776448b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual features\n",
    "# HighBP\n",
    "high_bp_vis = diabetes_data[\"HighBP\"].astype(bool)\n",
    "sns.barplot(data=high_bp_vis.value_counts())\n",
    "plt.title(\"Distribution of High Blood Pressure Status in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"High Blood Pressure Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"COUNTS:\\n{high_bp_vis.value_counts()}\")\n",
    "print(f\"PROPORTIONS:\\n{high_bp_vis.value_counts() / len(high_bp_vis)}\")\n",
    "\n",
    "# HighChol\n",
    "high_chol_vis = diabetes_data[\"HighChol\"].astype(bool)\n",
    "sns.barplot(data=high_chol_vis.value_counts())\n",
    "plt.title(\"Distribution of High Cholesterol Status in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"High Cholesterol Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"COUNTS:\\n{high_chol_vis.value_counts()}\")\n",
    "print(f\"PROPORTIONS:\\n{high_chol_vis.value_counts() / len(high_chol_vis)}\")\n",
    "\n",
    "# CholCheck\n",
    "chol_check_vis = diabetes_data[\"CholCheck\"].astype(bool)\n",
    "sns.barplot(data=chol_check_vis.value_counts())\n",
    "plt.title(\"Distribution of Cholesterol Check Status in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"Cholesterol Check Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"COUNTS:\\n{chol_check_vis.value_counts()}\")\n",
    "print(f\"PROPORTIONS:\\n{chol_check_vis.value_counts() / len(chol_check_vis)}\")\n",
    "\n",
    "# Smoker\n",
    "smoker_vis = diabetes_data[\"Smoker\"].astype(bool)\n",
    "sns.barplot(data=smoker_vis.value_counts())\n",
    "plt.title(\"Distribution of Smoker Status in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"Smoker Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"COUNTS:\\n{smoker_vis.value_counts()}\")\n",
    "print(f\"PROPORTIONS:\\n{smoker_vis.value_counts() / len(smoker_vis)}\")\n",
    "\n",
    "# Stroke\n",
    "stroke_vis = diabetes_data[\"Stroke\"].astype(bool)\n",
    "sns.barplot(data=stroke_vis.value_counts())\n",
    "plt.title(\"Distribution of Stroke Status in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"Stroke Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/stroke.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"COUNTS:\\n{stroke_vis.value_counts()}\")\n",
    "print(f\"PROPORTIONS:\\n{stroke_vis.value_counts() / len(stroke_vis)}\")\n",
    "\n",
    "# HeartDiseaseorAttack\n",
    "hdoa_vis = diabetes_data[\"HeartDiseaseorAttack\"].astype(bool)\n",
    "sns.barplot(data=hdoa_vis.value_counts())\n",
    "plt.title(\"Distribution of Heart Disease/Attack Status in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"Heart Disease/Attack Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"COUNTS:\\n{hdoa_vis.value_counts()}\")\n",
    "print(f\"PROPORTIONS:\\n{hdoa_vis.value_counts() / len(hdoa_vis)}\")\n",
    "\n",
    "# PhysActivity\n",
    "phys_activity_vis = diabetes_data[\"PhysActivity\"].astype(bool)\n",
    "sns.barplot(data=phys_activity_vis.value_counts())\n",
    "plt.title(\"Distribution of Physical Activity Status in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"Physical Activity Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"COUNTS:\\n{phys_activity_vis.value_counts()}\")\n",
    "print(f\"PROPORTIONS:\\n{phys_activity_vis.value_counts() / len(phys_activity_vis)}\")\n",
    "\n",
    "# Fruits\n",
    "fruits_vis = diabetes_data[\"Fruits\"].astype(bool)\n",
    "sns.barplot(data=fruits_vis.value_counts())\n",
    "plt.title(\"Distribution of Daily Fruit Consumption Status in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"Daily Fruit Consumption Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"COUNTS:\\n{fruits_vis.value_counts()}\")\n",
    "print(f\"PROPORTIONS:\\n{fruits_vis.value_counts() / len(fruits_vis)}\")\n",
    "\n",
    "# Veggies\n",
    "veggies_vis = diabetes_data[\"Veggies\"].astype(bool)\n",
    "sns.barplot(data=veggies_vis.value_counts())\n",
    "plt.title(\"Distribution of Daily Vegetable Consumption Status in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"Daily Vegetable Consumption Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"COUNTS:\\n{veggies_vis.value_counts()}\")\n",
    "print(f\"PROPORTIONS:\\n{veggies_vis.value_counts() / len(veggies_vis)}\")\n",
    "\n",
    "# HvyAlcoholConsump\n",
    "alc_vis = diabetes_data[\"HvyAlcoholConsump\"].astype(bool)\n",
    "sns.barplot(data=alc_vis.value_counts())\n",
    "plt.title(\"Distribution of Heavy Alcohol Consumption Status in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"Heavy Alcohol Consumption Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"COUNTS:\\n{alc_vis.value_counts()}\")\n",
    "print(f\"PROPORTIONS:\\n{alc_vis.value_counts() / len(alc_vis)}\")\n",
    "\n",
    "# AnyHealthcare\n",
    "health_vis = diabetes_data[\"AnyHealthcare\"].astype(bool)\n",
    "sns.barplot(data=health_vis.value_counts())\n",
    "plt.title(\"Distribution of Healthcare Ownership Status in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"Healthcare Ownership Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/health.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"COUNTS:\\n{health_vis.value_counts()}\")\n",
    "print(f\"PROPORTIONS:\\n{health_vis.value_counts() / len(health_vis)}\")\n",
    "\n",
    "# NoDocbcCost\n",
    "no_doc_vis = diabetes_data[\"NoDocbcCost\"].astype(bool)\n",
    "sns.barplot(data=no_doc_vis.value_counts())\n",
    "plt.title(\"Distribution of Cost-Related Doctor Avoidance Status in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"Cost-Related Doctor Avoidance Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"COUNTS:\\n{no_doc_vis.value_counts()}\")\n",
    "print(f\"PROPORTIONS:\\n{no_doc_vis.value_counts() / len(no_doc_vis)}\")\n",
    "\n",
    "# DiffWalk\n",
    "diff_walks_vis = diabetes_data[\"DiffWalk\"].astype(bool)\n",
    "sns.barplot(data=diff_walks_vis.value_counts())\n",
    "plt.title(\"Distribution of Walking Difficulty Status in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"Walking Difficulty Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"COUNTS:\\n{diff_walks_vis.value_counts()}\")\n",
    "print(f\"PROPORTIONS:\\n{diff_walks_vis.value_counts() / len(diff_walks_vis)}\")\n",
    "\n",
    "# Sex\n",
    "sex_vis = diabetes_data[\"Sex\"].replace({0 : \"Female\", 1 : \"Male\"})\n",
    "sns.barplot(data=sex_vis.value_counts())\n",
    "plt.title(\"Distribution of Sex in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"Sex\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"COUNTS:\\n{sex_vis.value_counts()}\")\n",
    "print(f\"PROPORTIONS:\\n{sex_vis.value_counts() / len(sex_vis)}\")\n",
    "\n",
    "\n",
    "# GenHlth\n",
    "genhlth_vals = [\n",
    "    \"Excellent\",\n",
    "    \"Very Good\",\n",
    "    \"Good\",\n",
    "    \"Fair\",\n",
    "    \"Poor\"\n",
    "]\n",
    "\n",
    "genhlth_vis = diabetes_data[\"GenHlth\"].astype(int)\n",
    "to_plot = genhlth_vis.value_counts().sort_index()\n",
    "to_plot.index = genhlth_vals\n",
    "sns.barplot(data=to_plot)\n",
    "plt.title(\"Distribution of Self-Assessed General Health Score in Diabetes Dataset\")\n",
    "plt.xlabel(\"Self-Assessed General Health Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"SUMMARY STATISTICS:\\n{genhlth_vis.describe()}\")\n",
    "\n",
    "# Age\n",
    "age_vals = [\n",
    "    \"18-24\",\n",
    "    \"25-29\",\n",
    "    \"30-34\",\n",
    "    \"35-39\",\n",
    "    \"40-44\",\n",
    "    \"45-49\",\n",
    "    \"50-54\",\n",
    "    \"55-59\",\n",
    "    \"60-64\",\n",
    "    \"65-69\",\n",
    "    \"70-74\",\n",
    "    \"75-79\",\n",
    "    \">80\"\n",
    "]\n",
    "\n",
    "age_vis = diabetes_data[\"Age\"].astype(int)\n",
    "to_plot = age_vis.value_counts().sort_index()\n",
    "to_plot.index = age_vals\n",
    "sns.barplot(data=to_plot)\n",
    "plt.title(\"Distribution of Age Category in Diabetes Dataset\")\n",
    "plt.xlabel(\"Age Category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/age.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"SUMMARY STATISTICS:\\n{age_vis.describe()}\")\n",
    "\n",
    "# Education\n",
    "edu_vals = [\n",
    "    \"Never Attended/Only K\",\n",
    "    \"Grades 1-8\",\n",
    "    \"Grades 9-11\",\n",
    "    \"Grade 12/GED\",\n",
    "    \"College (1-3 years)\",\n",
    "    \"College (4 years)\"\n",
    "]\n",
    "\n",
    "edu_vis = diabetes_data[\"Education\"].astype(int)\n",
    "to_plot = edu_vis.value_counts().sort_index()\n",
    "to_plot.index = edu_vals\n",
    "sns.barplot(data=to_plot, orient=\"h\")\n",
    "plt.title(\"Distribution of Education Level in Diabetes Dataset\")\n",
    "plt.ylabel(\"Education Level\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"SUMMARY STATISTICS:\\n{edu_vis.describe()}\")\n",
    "\n",
    "# Income\n",
    "income_vals = [\n",
    "    \"<10k\",\n",
    "    \"10k-<15k\",\n",
    "    \"15k-<20k\",\n",
    "    \"20k-<25k\",\n",
    "    \"25k-<35k\",\n",
    "    \"35k-<50k\",\n",
    "    \"50k-<75k\",\n",
    "    \">75k\"\n",
    "]\n",
    "\n",
    "income_vis = diabetes_data[\"Income\"].astype(int)\n",
    "to_plot = income_vis.value_counts().sort_index()\n",
    "to_plot.index = income_vals\n",
    "sns.barplot(data=to_plot, orient=\"h\")\n",
    "plt.title(\"Distribution of Income in Diabetes Dataset\")\n",
    "plt.ylabel(\"Income\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"SUMMARY STATISTICS:\\n{income_vis.describe()}\")\n",
    "\n",
    "# BMI\n",
    "bmi_vis = diabetes_data[\"BMI\"]\n",
    "bmi_bins = np.arange(0, 102, 3)\n",
    "sns.violinplot(bmi_vis)\n",
    "plt.title(\"Distribution of BMI in Diabetes Dataset\")\n",
    "plt.ylabel(\"BMI\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/bmi.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"SUMMARY STATISTICS:\\n{bmi_vis.describe()}\")\n",
    "\n",
    "# MentHlth\n",
    "ment_vis = diabetes_data[\"MentHlth\"]\n",
    "sns.boxplot(ment_vis)\n",
    "plt.title(\"Distribution of Days of Poor Mental Health in Previous 30 in Diabetes Dataset\")\n",
    "plt.ylabel(\"Days\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"SUMMARY STATISTICS:\\n{ment_vis.describe()}\")\n",
    "\n",
    "# PhysHlth\n",
    "phys_vis = diabetes_data[\"PhysHlth\"]\n",
    "sns.boxplot(phys_vis)\n",
    "plt.title(\"Distribution of Days of Illness/Injury in  Previous 30 in Diabetes Dataset\")\n",
    "plt.ylabel(\"Days\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(f\"SUMMARY STATISTICS:\\n{phys_vis.describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fc702e-3911-4739-bb80-d8aa267c43e1",
   "metadata": {},
   "source": [
    "*Feature combinations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb173cfa-dc00-470e-b7e9-b029d4455b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinations of features\n",
    "# analyze correlation between all features\n",
    "sns.heatmap(X.corr(), cmap=\"vlag\", vmin=-1, vmax=1, cbar_kws={'label': 'Pearson Correlation Coefficient'})\n",
    "plt.title(\"Pearson Correlations Between Features\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/feature_corr.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# analyze correlation with target variable\n",
    "diabetes_data_corr = pd.DataFrame(columns=X.columns)\n",
    "for feature in X.columns:\n",
    "    diabetes_data_corr[feature] = pearsonr(\n",
    "        diabetes_data[feature],\n",
    "        diabetes_data[\"Diabetes_binary\"]\n",
    "    )\n",
    "sns.barplot(diabetes_data_corr, orient=\"h\", errorbar=None)\n",
    "plt.xlim((-1,1))\n",
    "plt.xlabel(\"Pearson Correlation Coefficient\")\n",
    "plt.title(\"Pearson Correlations Between Features/Target Variable\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/target_corr.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# relationship between general and mental health\n",
    "sns.violinplot(data=X, x=\"GenHlth\", y=\"MentHlth\")\n",
    "plt.title(\"Relationship Between Mental Health Score and Physical Health in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"Self-Assessed General Health Score\")\n",
    "plt.ylabel(\"Days of Poor Mental Health in Previous 30\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# relationship between general and physical health\n",
    "sns.violinplot(data=X, x=\"GenHlth\", y=\"PhysHlth\")\n",
    "plt.title(\"Relationship Between General Health Score and Physical Health in CDC Diabetes Dataset\")\n",
    "plt.xlabel(\"Self-Assessed General Health Score\")\n",
    "plt.ylabel(\"Days of Illness/Injury in Previous 30\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ff84c-0b45-416f-bbc2-5e932f3db1d8",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3125df5d-8b52-4fbc-bf1a-65b269f28365",
   "metadata": {},
   "source": [
    "*Logistic regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1af6b1-46fc-4241-81fd-bf6f7e102cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [7, 42, 65, 2004, 2026]\n",
    "preprocessor = ColumnTransformer(transformers=[(\"ss\", StandardScaler(), X.columns)])\n",
    "logreg_params = {\n",
    "    \"logisticregression__C\" : np.logspace(-3, 3, 7),\n",
    "    \"logisticregression__l1_ratio\" : np.linspace(0.1, 0.9, 5),\n",
    "}\n",
    "\n",
    "test_scores = []\n",
    "cv_scores = []\n",
    "logreg_results = {\n",
    "    \"seed\" : [],\n",
    "    \"cv_scores\" : [],\n",
    "    \"test_scores\" : [],\n",
    "    \"models\" : [],\n",
    "    \"results\" : [],\n",
    "    \"params\" : []\n",
    "}\n",
    "for rs in random_states:\n",
    "    print(f\"Processing state {rs}...\")\n",
    "    ti = time.time()\n",
    "\n",
    "    # add random state to results\n",
    "    logreg_results[\"seed\"].append(rs)\n",
    "\n",
    "    # split into cross-validation (80%) and testing (20%) sets\n",
    "    X_cv, X_test, y_cv, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=rs)\n",
    "\n",
    "    # initialize classifier\n",
    "    clf = LogisticRegression(class_weight=\"balanced\", max_iter=10000, penalty=\"elasticnet\", solver=\"saga\", random_state=rs)\n",
    "\n",
    "    # create pipeline with preprocessor\n",
    "    pipe = make_pipeline(preprocessor, clf)\n",
    "\n",
    "    # initialize StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=rs)\n",
    "\n",
    "    # initialize GridSearchCV\n",
    "    gscv = GridSearchCV(pipe, param_grid=logreg_params, cv=skf, scoring=\"f1\", n_jobs=-1, return_train_score=True)\n",
    "\n",
    "    # tune hyperparameters\n",
    "    gscv.fit(X_cv, y_cv)\n",
    "\n",
    "    # get best CV/test scores\n",
    "    cv_score = gscv.best_score_\n",
    "    test_score = f1_score(y_test, gscv.predict(X_test))\n",
    "\n",
    "    # store CV results for this seed\n",
    "    logreg_results[\"results\"].append(pd.DataFrame(gscv.cv_results_))\n",
    "\n",
    "    # store scores and models for this seed\n",
    "    logreg_results[\"test_scores\"].append(test_score)\n",
    "    logreg_results[\"cv_scores\"].append(cv_score)\n",
    "    logreg_results[\"models\"].append(gscv.best_estimator_)\n",
    "    logreg_results[\"params\"].append(gscv.best_params_)\n",
    "    print(f\"...took {time.time() - ti} seconds\")\n",
    "\n",
    "with open(\"../results/logreg_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(logreg_results, f)\n",
    "print(\"Saved results!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1476c0c-8c30-4994-a3fe-6a97b2395d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores, cv_scores = logreg_results[\"test_scores\"], logreg_results[\"cv_scores\"]\n",
    "print(f\"Test results for logistic regression: f1 score = {np.mean(test_scores):.3f} +/- {np.std(test_scores):.3f}\")\n",
    "print(f\"CV results for logistic regression: f1 score = {np.mean(cv_scores):.3f} +/- {np.std(cv_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e487c163-5940-4ada-ab99-07d773b9621a",
   "metadata": {},
   "source": [
    "*Random Forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f480d-b3a3-471f-a2f3-5ba98ddbc157",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [7, 42, 65, 2004, 2026]\n",
    "preprocessor = ColumnTransformer(transformers=[(\"ss\", StandardScaler(), X.columns)])\n",
    "rf_params = {\n",
    "    \"randomforestclassifier__max_features\" : np.linspace(0.1, 0.9, 5),\n",
    "    \"randomforestclassifier__max_depth\" : np.array([3, 5, 10, 30])\n",
    "}\n",
    "\n",
    "test_scores = []\n",
    "cv_scores = []\n",
    "rf_results = {\n",
    "    \"seed\" : [],\n",
    "    \"cv_scores\" : [],\n",
    "    \"test_scores\" : [],\n",
    "    \"models\" : [],\n",
    "    \"results\" : [],\n",
    "    \"params\" : []\n",
    "}\n",
    "for rs in random_states:\n",
    "    print(f\"Processing state {rs}...\")\n",
    "    ti = time.time()\n",
    "\n",
    "    # add random state to results\n",
    "    rf_results[\"seed\"].append(rs)\n",
    "\n",
    "    # split into cross-validation (80%) and testing (20%) sets\n",
    "    X_cv, X_test, y_cv, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=rs)\n",
    "\n",
    "    # initialize classifier\n",
    "    clf = RandomForestClassifier(random_state=rs, class_weight=\"balanced\")\n",
    "\n",
    "    # create pipeline with preprocessor\n",
    "    pipe = make_pipeline(preprocessor, clf)\n",
    "\n",
    "    # initialize StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=rs)\n",
    "\n",
    "    # initialize GridSearchCV\n",
    "    gscv = GridSearchCV(pipe, param_grid=rf_params, cv=skf, scoring=\"f1\", n_jobs=-1, return_train_score=True)\n",
    "\n",
    "    # tune hyperparameters\n",
    "    gscv.fit(X_cv, y_cv)\n",
    "\n",
    "    # get best CV/test scores\n",
    "    cv_score = gscv.best_score_\n",
    "    test_score = f1_score(y_test, gscv.predict(X_test))\n",
    "\n",
    "    # store CV results for this seed\n",
    "    rf_results[\"results\"].append(pd.DataFrame(gscv.cv_results_))\n",
    "\n",
    "    # store scores and models for this seed\n",
    "    rf_results[\"test_scores\"].append(test_score)\n",
    "    rf_results[\"cv_scores\"].append(cv_score)\n",
    "    rf_results[\"models\"].append(gscv.best_estimator_)\n",
    "    rf_results[\"params\"].append(gscv.best_params_)\n",
    "\n",
    "    print(f\"...took {time.time() - ti} seconds\")\n",
    "\n",
    "with open(\"../results/rf_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf_results, f)\n",
    "print(\"Saved results!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf184dc-8d88-4e5f-b9c1-e4d4214dae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores, cv_scores = rf_results[\"test_scores\"], rf_results[\"cv_scores\"]\n",
    "print(f\"Test results for random forest: f1 score = {np.mean(test_scores):.3f} +/- {np.std(test_scores):.3f}\")\n",
    "print(f\"CV results for random forest: f1 score = {np.mean(cv_scores):.3f} +/- {np.std(cv_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ce376-1bec-4cca-b7a1-07e428475d55",
   "metadata": {},
   "source": [
    "*Decision Tree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c469224-095d-4498-bd64-7c6168ae7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [7, 42, 65, 2004, 2026]\n",
    "preprocessor = ColumnTransformer(transformers=[(\"ss\", StandardScaler(), X.columns)])\n",
    "dt_params = {\n",
    "    \"decisiontreeclassifier__max_features\" : np.linspace(0.1, 0.9, 5),\n",
    "    \"decisiontreeclassifier__max_depth\" : np.array([3, 5, 10, 30]),\n",
    "}\n",
    "\n",
    "test_scores = []\n",
    "cv_scores = []\n",
    "dt_results = {\n",
    "    \"seed\" : [],\n",
    "    \"cv_scores\" : [],\n",
    "    \"test_scores\" : [],\n",
    "    \"models\" : [],\n",
    "    \"results\" : [],\n",
    "    \"params\" : []\n",
    "}\n",
    "for rs in random_states:\n",
    "    print(f\"Processing state {rs}...\")\n",
    "    ti = time.time()\n",
    "\n",
    "    # add random state to results\n",
    "    dt_results[\"seed\"].append(rs)\n",
    "\n",
    "    # split into cross-validation (80%) and testing (20%) sets\n",
    "    X_cv, X_test, y_cv, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=rs)\n",
    "\n",
    "    # initialize classifier\n",
    "    clf = DecisionTreeClassifier(class_weight=\"balanced\", random_state=rs)\n",
    "\n",
    "    # create pipeline with preprocessor\n",
    "    pipe = make_pipeline(preprocessor, clf)\n",
    "\n",
    "    # initialize StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=rs)\n",
    "\n",
    "    # initialize GridSearchCV\n",
    "    gscv = GridSearchCV(pipe, param_grid=dt_params, cv=skf, scoring=\"f1\", n_jobs=-1, return_train_score=True)\n",
    "\n",
    "    # tune hyperparameters\n",
    "    gscv.fit(X_cv, y_cv)\n",
    "\n",
    "    # get best CV/test scores\n",
    "    cv_score = gscv.best_score_\n",
    "    test_score = f1_score(y_test, gscv.predict(X_test))\n",
    "\n",
    "    # store CV results for this seed\n",
    "    dt_results[\"results\"].append(pd.DataFrame(gscv.cv_results_))\n",
    "\n",
    "    # store scores and models for this seed\n",
    "    dt_results[\"test_scores\"].append(test_score)\n",
    "    dt_results[\"cv_scores\"].append(cv_score)\n",
    "    dt_results[\"models\"].append(gscv.best_estimator_)\n",
    "    dt_results[\"params\"].append(gscv.best_params_)\n",
    "\n",
    "    print(f\"...took {time.time() - ti} seconds\")\n",
    "\n",
    "with open(\"../results/dt_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dt_results, f)\n",
    "print(\"Saved results!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbbe6a-ae84-4723-a1d6-769ee6924a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores, cv_scores = dt_results[\"test_scores\"], dt_results[\"cv_scores\"]\n",
    "print(f\"Test results for decision tree: f1 score = {np.mean(test_scores):.3f} +/- {np.std(test_scores):.3f}\")\n",
    "print(f\"CV results for decision tree: f1 score = {np.mean(cv_scores):.3f} +/- {np.std(cv_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfce1f1-7871-4506-9eae-38819709c44b",
   "metadata": {},
   "source": [
    "*XGBoost*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b18be4-d7ae-4da0-9cd7-7487a1213114",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [7, 42, 65, 2004, 2026]\n",
    "xgb_es_params = {\n",
    "    \"max_depth\" : np.array([3, 5, 10, 30, 50]),\n",
    "    \"reg_lambda\" : np.logspace(-3, 3, 7)\n",
    "}\n",
    "\n",
    "test_scores = []\n",
    "cv_scores = []\n",
    "xgb_es_results = {\n",
    "    \"seed\" : [],\n",
    "    \"cv_scores\" : [],\n",
    "    \"test_scores\" : [],\n",
    "    \"models\" : [],\n",
    "    \"results\" : [],\n",
    "    \"params\" : []\n",
    "}\n",
    "\n",
    "def eval_xgb_param(X_cv, y_cv, cv, param, rs):\n",
    "    \"\"\"\n",
    "    GridSearchCV-like function that allows parallelization\n",
    "    of XGBoost parameter grid search with early stopping \n",
    "    using k-fold cross-validation.\n",
    "    \"\"\"\n",
    "\n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "    models = []\n",
    "    # split with cross-validator\n",
    "    for train_idx, val_idx in cv.split(X_cv, y_cv):\n",
    "\n",
    "        # get folds\n",
    "        X_train, y_train = X_cv.iloc[train_idx], y_cv.iloc[train_idx]\n",
    "        X_val, y_val = X_cv.iloc[val_idx], y_cv.iloc[val_idx]\n",
    "        weights = compute_sample_weight(\"balanced\", y_train)\n",
    "\n",
    "        # preprocess data\n",
    "        preprocessor = ColumnTransformer(transformers=[(\"ss\", StandardScaler(), X.columns)])\n",
    "        X_train_prep = preprocessor.fit_transform(X_train)\n",
    "        X_val_prep = preprocessor.transform(X_val)\n",
    "\n",
    "        # fit classifier on training data\n",
    "        clf = XGBClassifier(subsample=0.66, learning_rate=0.03, early_stopping_rounds=50,\n",
    "                            colsample_bytree=0.9, random_state=rs, **param)\n",
    "        clf.fit(X_train_prep, y_train, sample_weight=weights, eval_set=[(X_val_prep, y_val)], verbose=False)\n",
    "\n",
    "        # evaluate on training and validation sets\n",
    "        train_score = f1_score(y_train, clf.predict(X_train_prep))\n",
    "        val_score = f1_score(y_val, clf.predict(X_val_prep))\n",
    "\n",
    "        # add to list\n",
    "        train_scores.append(train_score)\n",
    "        val_scores.append(val_score)\n",
    "\n",
    "        # store model configuration\n",
    "        models.append((preprocessor, clf))\n",
    "\n",
    "    # get mean scores across splits\n",
    "    mean_train_score = np.mean(train_scores)\n",
    "    mean_val_score = np.mean(val_scores)\n",
    "\n",
    "    # get best preprocessor/classifier\n",
    "    best_est = models[np.argmax(val_scores)]\n",
    "\n",
    "    # finally, the last hyperparameter\n",
    "    n_est = best_est[1].best_iteration\n",
    "    return mean_train_score, mean_val_score, best_est, n_est\n",
    "\n",
    "for rs in random_states:\n",
    "    print(f\"Processing state {rs}...\")\n",
    "    ti = time.time()\n",
    "\n",
    "    # add random state to results\n",
    "    xgb_es_results[\"seed\"].append(rs)\n",
    "\n",
    "    # split into cross-validation (80%) and testing (20%) sets\n",
    "    X_cv, X_test, y_cv, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=rs)\n",
    "\n",
    "    # make parameter grid\n",
    "    pg = list(ParameterGrid(xgb_es_params))\n",
    "\n",
    "    # initialize k-fold\n",
    "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=rs)\n",
    "\n",
    "    # paralellize hyperparameter search\n",
    "    results = Parallel(n_jobs=-1)(delayed(eval_xgb_param)(X_cv, y_cv, skf, param, rs) for param in pg)\n",
    "    \n",
    "    # unpack results\n",
    "    train_scores = [r[0] for r in results]\n",
    "    val_scores = [r[1] for r in results]\n",
    "    models = [r[2] for r in results]\n",
    "    estimators = [r[3] for r in results]\n",
    "\n",
    "    # find results with best validation score\n",
    "    best_val_idx = np.argmax(val_scores)\n",
    "    cv_score = val_scores[best_val_idx]\n",
    "    preprocessor, clf = models[best_val_idx]\n",
    "    params = pg[best_val_idx]\n",
    "    params[\"n_estimators\"] = estimators[best_val_idx]\n",
    "\n",
    "    # test\n",
    "    X_test_prep = preprocessor.transform(X_test)\n",
    "    test_score = f1_score(y_test, clf.predict(X_test_prep))\n",
    "\n",
    "    cv_results = {\n",
    "        \"train_scores\" : train_scores,\n",
    "        \"val_scores\" : val_scores,\n",
    "        \"parameters\" : pg,\n",
    "        \"estimators\" : estimators\n",
    "    }\n",
    "    # store CV results for this seed\n",
    "    xgb_es_results[\"results\"].append(pd.DataFrame(cv_results))\n",
    "\n",
    "    # store scores and models for this seed\n",
    "    xgb_es_results[\"test_scores\"].append(test_score)\n",
    "    xgb_es_results[\"cv_scores\"].append(cv_score)\n",
    "    xgb_es_results[\"models\"].append((preprocessor, clf))\n",
    "    xgb_es_results[\"params\"].append(params)\n",
    "\n",
    "    print(f\"...took {time.time() - ti} seconds\")\n",
    "\n",
    "with open(\"../results/xgb_es_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(xgb_es_results, f)\n",
    "print(\"Saved results!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3247d-7540-4547-ba03-01e4653b8d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores, cv_scores = xgb_es_results[\"test_scores\"], xgb_es_results[\"cv_scores\"]\n",
    "print(f\"Test results for XGBoost: f1 score = {np.mean(test_scores):.3f} +/- {np.std(test_scores):.3f}\")\n",
    "print(f\"CV results for XGBoost: f1 score = {np.mean(cv_scores):.3f} +/- {np.std(cv_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8fbbbf-2931-4648-81f7-5ddbad89e900",
   "metadata": {},
   "source": [
    "*XGBoost Optimization Effort*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650eef47-3ac5-40d3-9735-48d2a20acedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [7, 42, 65, 2004, 2026]\n",
    "xgb_es_opt_params = {\n",
    "    \"max_depth\" : np.array([100, 300]),\n",
    "    \"reg_lambda\" : np.array([10])\n",
    "}\n",
    "\n",
    "test_scores = []\n",
    "cv_scores = []\n",
    "xgb_es_opt_results = {\n",
    "    \"seed\" : [],\n",
    "    \"cv_scores\" : [],\n",
    "    \"test_scores\" : [],\n",
    "    \"models\" : [],\n",
    "    \"results\" : [],\n",
    "    \"params\" : []\n",
    "}\n",
    "\n",
    "def eval_xgb_param(X_cv, y_cv, cv, param, rs):\n",
    "    \"\"\"\n",
    "    GridSearchCV-like function that allows parallelization\n",
    "    of XGBoost parameter grid search with early stopping \n",
    "    using k-fold cross-validation.\n",
    "    \"\"\"\n",
    "\n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "    models = []\n",
    "    # split with cross-validator\n",
    "    for train_idx, val_idx in cv.split(X_cv, y_cv):\n",
    "\n",
    "        # get folds\n",
    "        X_train, y_train = X_cv.iloc[train_idx], y_cv.iloc[train_idx]\n",
    "        X_val, y_val = X_cv.iloc[val_idx], y_cv.iloc[val_idx]\n",
    "        weights = compute_sample_weight(\"balanced\", y_train)\n",
    "\n",
    "        # preprocess data\n",
    "        preprocessor = ColumnTransformer(transformers=[(\"ss\", StandardScaler(), X.columns)])\n",
    "        X_train_prep = preprocessor.fit_transform(X_train)\n",
    "        X_val_prep = preprocessor.transform(X_val)\n",
    "\n",
    "        # fit classifier on training data\n",
    "        clf = XGBClassifier(subsample=0.66, learning_rate=0.03, early_stopping_rounds=50,\n",
    "                            colsample_bytree=0.9, random_state=rs, **param)\n",
    "        clf.fit(X_train_prep, y_train, sample_weight=weights, eval_set=[(X_val_prep, y_val)], verbose=False)\n",
    "\n",
    "        # evaluate on training and validation sets\n",
    "        train_score = f1_score(y_train, clf.predict(X_train_prep))\n",
    "        val_score = f1_score(y_val, clf.predict(X_val_prep))\n",
    "\n",
    "        # add to list\n",
    "        train_scores.append(train_score)\n",
    "        val_scores.append(val_score)\n",
    "\n",
    "        # store model configuration\n",
    "        models.append((preprocessor, clf))\n",
    "\n",
    "    # get mean scores across splits\n",
    "    mean_train_score = np.mean(train_scores)\n",
    "    mean_val_score = np.mean(val_scores)\n",
    "\n",
    "    # get best preprocessor/classifier\n",
    "    best_est = models[np.argmax(val_scores)]\n",
    "\n",
    "    # finally, the last hyperparameter\n",
    "    n_est = best_est[1].best_iteration\n",
    "    return mean_train_score, mean_val_score, best_est, n_est\n",
    "\n",
    "for rs in random_states:\n",
    "    print(f\"Processing state {rs}...\")\n",
    "    ti = time.time()\n",
    "\n",
    "    # add random state to results\n",
    "    xgb_es_opt_results[\"seed\"].append(rs)\n",
    "\n",
    "    # split into cross-validation (80%) and testing (20%) sets\n",
    "    X_cv, X_test, y_cv, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=rs)\n",
    "\n",
    "    # make parameter grid\n",
    "    pg = list(ParameterGrid(xgb_es_opt_params))\n",
    "\n",
    "    # initialize k-fold\n",
    "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=rs)\n",
    "\n",
    "    # paralellize hyperparameter search\n",
    "    results = Parallel(n_jobs=-1)(delayed(eval_xgb_param)(X_cv, y_cv, skf, param, rs) for param in pg)\n",
    "    \n",
    "    # unpack results\n",
    "    train_scores = [r[0] for r in results]\n",
    "    val_scores = [r[1] for r in results]\n",
    "    models = [r[2] for r in results]\n",
    "    estimators = [r[3] for r in results]\n",
    "\n",
    "    # find results with best validation score\n",
    "    best_val_idx = np.argmax(val_scores)\n",
    "    cv_score = val_scores[best_val_idx]\n",
    "    preprocessor, clf = models[best_val_idx]\n",
    "    params = pg[best_val_idx]\n",
    "    params[\"n_estimators\"] = estimators[best_val_idx]\n",
    "\n",
    "    # test\n",
    "    X_test_prep = preprocessor.transform(X_test)\n",
    "    test_score = f1_score(y_test, clf.predict(X_test_prep))\n",
    "\n",
    "    cv_results = {\n",
    "        \"train_scores\" : train_scores,\n",
    "        \"val_scores\" : val_scores,\n",
    "        \"parameters\" : pg,\n",
    "        \"estimators\" : estimators\n",
    "    }\n",
    "    # store CV results for this seed\n",
    "    xgb_es_opt_results[\"results\"].append(pd.DataFrame(cv_results))\n",
    "\n",
    "    # store scores and models for this seed\n",
    "    xgb_es_opt_results[\"test_scores\"].append(test_score)\n",
    "    xgb_es_opt_results[\"cv_scores\"].append(cv_score)\n",
    "    xgb_es_opt_results[\"models\"].append((preprocessor, clf))\n",
    "    xgb_es_opt_results[\"params\"].append(params)\n",
    "\n",
    "    print(f\"...took {time.time() - ti} seconds\")\n",
    "\n",
    "with open(\"../results/xgb_es_opt_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(xgb_es_opt_results, f)\n",
    "print(\"Saved results!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a105cf1-995a-428f-8881-8559a2bbad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores, cv_scores = xgb_es_opt_results[\"test_scores\"], xgb_es_opt_results[\"cv_scores\"]\n",
    "print(f\"Test results for XGBoost: f1 score = {np.mean(test_scores):.3f} +/- {np.std(test_scores):.3f}\")\n",
    "print(f\"CV results for XGBoost: f1 score = {np.mean(cv_scores):.3f} +/- {np.std(cv_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed23ed0-c317-49b6-86d3-6b7e4e8e6709",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35b9b53-b940-4641-b0bd-35472a33e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all saved final results and combine\n",
    "with open(\"../results/logreg_results.pkl\", \"rb\") as f:\n",
    "    logreg_final_results = pickle.load(f)\n",
    "with open(\"../results/rf_results.pkl\", \"rb\") as f:\n",
    "    rf_final_results = pickle.load(f)\n",
    "with open(\"../results/dt_results.pkl\", \"rb\") as f:\n",
    "    dt_final_results = pickle.load(f)\n",
    "with open(\"../results/xgb_es_results.pkl\", \"rb\") as f:\n",
    "    xgb_es_final_results = pickle.load(f)\n",
    "with open(\"../results/xgb_es_opt_results.pkl\", \"rb\") as f:\n",
    "    xgb_es_opt_final_results = pickle.load(f)\n",
    "\n",
    "final_results = {\n",
    "    \"logreg\" : logreg_final_results,\n",
    "    \"rf\" : rf_final_results,\n",
    "    \"dt\" : dt_final_results,\n",
    "    \"xgb\" : xgb_es_final_results,\n",
    "    \"xgb_opt\" : xgb_es_opt_final_results\n",
    "}\n",
    "name_sub = {\n",
    "    \"logreg\" : \"Logistic\\nRegression\",\n",
    "    \"rf\" : \"Random\\nForest\",\n",
    "    \"dt\" : \"Decision\\nTree\",\n",
    "    \"xgb\" : \"XGBoost\",\n",
    "    \"xgb_opt\" : \"XGBoost\\n(optimized)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c466c19c-5f7b-47ca-95fb-cb4faed7227d",
   "metadata": {},
   "source": [
    "*CV/test scores*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d440e65-ae80-43a4-989d-63a165332cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores = {\n",
    "    \"Model\" : [],\n",
    "    \"Mean F1 Score\" : [],\n",
    "    \"Type\" : []\n",
    "}\n",
    "# update with model seeds and test scores for that seed\n",
    "for model, result in final_results.items():\n",
    "    for cv_score in result[\"cv_scores\"]:\n",
    "        final_scores[\"Model\"].append(name_sub[model])\n",
    "        final_scores[\"Mean F1 Score\"].append(cv_score)\n",
    "        final_scores[\"Type\"].append(\"CV\")\n",
    "    for test_score in result[\"test_scores\"]:\n",
    "        final_scores[\"Model\"].append(name_sub[model])\n",
    "        final_scores[\"Mean F1 Score\"].append(test_score)\n",
    "        final_scores[\"Type\"].append(\"Test\")\n",
    "\n",
    "# calculate baseline F1\n",
    "p1 = y[y==1].shape[0] / y.shape[0]\n",
    "f1_baseline = 2 * p1 / (1 + p1)\n",
    "\n",
    "# I am unbelievably lucky that model performance increased alphabetically!\n",
    "final_scores = pd.DataFrame(final_scores).sort_values(\"Model\")\n",
    "sns.catplot(data=final_scores, x=\"Model\", y=\"Mean F1 Score\",\n",
    "            hue=\"Type\", kind=\"bar\")\n",
    "plt.axhline(f1_baseline, linestyle=\"--\", color=\"red\", label=\"baseline\")\n",
    "plt.title(\"Best Cross-Validation and Test Scores by Model\")\n",
    "plt.savefig(\"../figures/cv_test_scores.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9937fb3-4044-4537-b480-49ad85d0b447",
   "metadata": {},
   "source": [
    "*Ideal hyperparameters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3caaa7-7600-4db3-a217-bf1815d997ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, result in final_results.items():\n",
    "    print(f\"--------Hyperparameters for {model}--------\")\n",
    "    for i, param_set in enumerate(result[\"params\"]):\n",
    "        print(f\"Seed : {result[\"seed\"][i]}\")\n",
    "        for param, val in param_set.items():\n",
    "            if \"xgb\" not in model:\n",
    "                param = param.split(\"__\")[1]\n",
    "            print(f\"{param} : {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7cbdc-58b1-4ee5-92f4-1f5b8e57d340",
   "metadata": {},
   "source": [
    "*Reproduce/verify model predictions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d9bac-83ea-4649-9b3e-980ad5eb1243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduce model predictions for each set\n",
    "# and save to master .csv\n",
    "\n",
    "# same random states as always\n",
    "random_states = [7, 42, 65, 2004, 2026]\n",
    "\n",
    "for i, rs in enumerate(random_states):\n",
    "\n",
    "    # copy to avoid mutating X, y\n",
    "    X_copy = X.copy(deep=True)\n",
    "    y_copy = y.copy(deep=True)\n",
    "\n",
    "    # get true labels\n",
    "    X_copy[\"true\"] = y_copy\n",
    "\n",
    "    # for use later\n",
    "    features = X.columns\n",
    "\n",
    "    # reproduce cv/test sets\n",
    "    X_cv, X_test, y_cv, y_test = train_test_split(X_copy, y_copy, stratify=y, test_size=0.2, random_state=rs)\n",
    "\n",
    "    # indicate which points are test and cv\n",
    "    X_copy.loc[X_cv.index,\"set\"] = \"cv\"\n",
    "    X_copy.loc[X_test.index,\"set\"] = \"test\"\n",
    "\n",
    "    # repredict all points with saved models\n",
    "    for model_name, result in final_results.items():\n",
    "\n",
    "        # find model for this random state\n",
    "        pipeline = result[\"models\"][i]\n",
    "\n",
    "        # get predictions for all points\n",
    "        X_copy[f\"{model_name}_pred\"] = pipeline[1].predict(pipeline[0].transform(X_copy[features]))\n",
    "\n",
    "        # very important reproducibility check\n",
    "        test_points = X_copy[X_copy[\"set\"] == \"test\"]\n",
    "        score = f1_score(test_points[\"true\"], test_points[f\"{model_name}_pred\"])\n",
    "        print(f\"Validated test score of {score:.3f}\")\n",
    "        assert score == result[\"test_scores\"][i]\n",
    "\n",
    "    X_copy.to_csv(f\"../results/seed_{rs}_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb10f0-f091-4e40-82f6-fc73a19d0dd5",
   "metadata": {},
   "source": [
    "*Confusion matrices*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e53b7d0-63c3-459e-8f8a-09a9d8851743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate confusion matrices on all test sets\n",
    "\n",
    "min_obs = None\n",
    "max_obs = None\n",
    "confusion_matrices = []\n",
    "random_states = [7, 42, 65, 2004, 2026]\n",
    "for model_name, result in final_results.items():\n",
    "\n",
    "    if model_name == \"xgb\":\n",
    "        print(f\"Skipping {model_name} in favor of optimized version...\")\n",
    "        continue\n",
    "\n",
    "    model_cms = []\n",
    "    f1s = []\n",
    "    for rs, model in zip(random_states, result[\"models\"]):\n",
    "\n",
    "        # reproduce test set\n",
    "        seed_df = pd.read_csv(f\"../results/seed_{rs}_predictions.csv\")\n",
    "        test_set = seed_df[seed_df[\"set\"] == \"test\"]\n",
    "        y_test_pred = test_set[f\"{model_name}_pred\"]\n",
    "        y_test = test_set[f\"true\"]\n",
    "        \n",
    "        # create confusion matrix for this seed\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_test_pred)\n",
    "        model_cms.append(cm)\n",
    "        p = cm[1,1] / (cm[0,1] + cm[1,1])\n",
    "        r = cm[1,1] / (cm[1,0] + cm[1,1])\n",
    "        f1s.append(2*p*r / (p + r))\n",
    "\n",
    "    # verify f1 score\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"F1 scores from CM: {np.array(f1s)}\")\n",
    "    print(f\"F1 scores saved: {np.array(result[\"test_scores\"])}\")\n",
    "\n",
    "    # average confusion matrices over seeds\n",
    "    mean_matrix = np.mean(model_cms, axis=0)\n",
    "\n",
    "    # normalize w.r.t. true conditions\n",
    "    mean_norm_matrix = np.array([x / np.sum(x) for x in mean_matrix])\n",
    "\n",
    "    # update minimum and maximum values if necessary\n",
    "    # this allows normalization for all confusion matrices\n",
    "    if min_obs is None or np.min(mean_norm_matrix) < min_obs:\n",
    "        min_obs = np.min(mean_norm_matrix)\n",
    "    if max_obs is None or np.max(mean_norm_matrix) > max_obs:\n",
    "        max_obs = np.max(mean_norm_matrix)\n",
    "    \n",
    "    # store mean normalized confusion matrix\n",
    "    confusion_matrices.append((model_name, mean_norm_matrix))\n",
    "\n",
    "# to normalize colorbars\n",
    "norm = Normalize(vmin=min_obs, vmax=max_obs)\n",
    "\n",
    "# make plot\n",
    "fig, axes = plt.subplots(2,2,figsize=(12,12))\n",
    "for ax, (model_name, cm) in zip(axes.flatten(), confusion_matrices):\n",
    "\n",
    "    # plot confusion matrix for this model\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=[\"Nondiabetic\", \"(Pre)Diabetic\"])\n",
    "    disp.plot(ax=ax)\n",
    "    disp.im_.set_norm(norm)\n",
    "    ax.set_title(name_sub[model_name])\n",
    "plt.suptitle(\"Confusion Matrices by Model\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/confusion_matrix.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215171a3-7720-4ce6-9033-abe91b60e2e0",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13beaace-5df8-4229-9759-0e010d59a965",
   "metadata": {},
   "source": [
    "*Global feature importances*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff463070-c189-47cc-ab46-4027bc2fd8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,2,figsize=(5*2,3*3))\n",
    "importance_results = {}\n",
    "imp_types = [\"cover\", \"gain\", \"total_cover\", \"total_gain\", \"weight\"]\n",
    "for ax, imp_type in zip(axes.flatten(), imp_types):\n",
    "    imps = []\n",
    "    for pipeline in final_results[\"xgb_opt\"][\"models\"]:\n",
    "        xgb_model = pipeline[1]\n",
    "        xgb_model.importance_type = imp_type\n",
    "        imps.append(xgb_model.feature_importances_)\n",
    "    avg_imps = np.mean(imps, axis=0)\n",
    "    importance_results[imp_type] = avg_imps\n",
    "    imp_df = pd.DataFrame(importance_results, index=X.columns)\n",
    "    sns.barplot(data=imp_df[imp_type].sort_values(ascending=False), orient=\"h\", ax=ax)\n",
    "axes[-1,-1].remove()\n",
    "plt.suptitle(\"XGBoost Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/xgb_feature_importances.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f1d64-6af9-427f-97e2-c079459ed80d",
   "metadata": {},
   "source": [
    "*Local feature importances*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5197dc95-6ca9-4e2e-90ac-6d6393af18a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_i = np.argmax(final_results[\"xgb_opt\"][\"test_scores\"])\n",
    "rs = final_results[\"xgb_opt\"][\"seed\"][best_model_i]\n",
    "pipeline = final_results[\"xgb_opt\"][\"models\"][best_model_i]\n",
    "    \n",
    "# get relevant preprocessor/XGBClassifier\n",
    "prep = pipeline[0]\n",
    "xgb_model = pipeline[1]\n",
    "\n",
    "# reproduce test set\n",
    "seed_df = pd.read_csv(f\"../results/seed_{rs}_predictions.csv\")\n",
    "\n",
    "test_set = seed_df[seed_df[\"set\"] == \"test\"]\n",
    "X_test = test_set[X.columns]\n",
    "y_test_pred = test_set[\"xgb_opt_pred\"]\n",
    "\n",
    "# sample 1000 points for global SHAP summary plot\n",
    "_, X_sample, _, _ = train_test_split(X_test, y_test_pred, test_size=0.01, stratify=y_test_pred, random_state=65)\n",
    "\n",
    "# scale appropriately\n",
    "X_sample_scaled = prep.transform(X_sample)\n",
    "\n",
    "# make explainer\n",
    "exp = shap.TreeExplainer(xgb_model)\n",
    "\n",
    "# find shap values\n",
    "sample_shap_vals = exp.shap_values(X_sample_scaled)\n",
    "\n",
    "# plot\n",
    "shap.summary_plot(sample_shap_vals, X_sample, feature_names=X_sample.columns, show=False)\n",
    "plt.title(\"Global SHAP Summary Plot\")\n",
    "plt.savefig(\"../figures/global_shap_1percent.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "    \n",
    "# find one random point from each class\n",
    "X_pos_sample = X_test[y_test_pred == 1].sample(n=2, random_state=65)\n",
    "X_neg_sample = X_test[y_test_pred == 0].sample(n=2, random_state=65)\n",
    "\n",
    "# combine into one sample\n",
    "X_sample = pd.concat([X_pos_sample, X_neg_sample])\n",
    "\n",
    "# scale data appropriately\n",
    "X_sample_scaled = prep.transform(X_sample)\n",
    "\n",
    "# get base value\n",
    "exp = shap.TreeExplainer(xgb_model)\n",
    "base_val = exp.expected_value\n",
    "\n",
    "# find SHAP values\n",
    "sample_shap_vals = exp.shap_values(X_sample_scaled)\n",
    "\n",
    "for i in range(X_sample.shape[0]):\n",
    "    plt.close() # extra safe - I had lots of weird bugs with making force plots\n",
    "    fp = shap.force_plot(base_value=base_val, shap_values=sample_shap_vals[i],\n",
    "                         features=X_sample.iloc[i], feature_names=X_sample.columns,\n",
    "                         link=\"logit\", matplotlib=True, show=False, text_rotation=30)\n",
    "    plt.savefig(f\"../figures/shap_{i}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
